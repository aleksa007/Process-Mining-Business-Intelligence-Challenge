{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutation algorithm, using combinations of two events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy\n",
    "import itertools\n",
    "from itertools import tee, combinations, permutations\n",
    "from progressbar import ProgressBar\n",
    "import datetime\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import time\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('./data/road-train-pre.csv', error_bad_lines=False)\n",
    "data_test = pd.read_csv('./data/road-test-pre.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['event time:timestamp'] = pd.to_datetime(data_train['event time:timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.sort_values(by=['case concept:name', 'event time:timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['day_of_week'] = data_train['event time:timestamp'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_train.to_csv(\"fixed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('fixed.csv', 'r')\n",
    "log = dict()\n",
    "with open('fixed.csv', 'r') as file:\n",
    "    next(file)\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        parts = line.split(',')\n",
    "        caseid = parts[2]\n",
    "\n",
    "        task = parts[3]\n",
    "        timestamp = parts[5]\n",
    "        day = parts[6]\n",
    "\n",
    "        if caseid not in log:\n",
    "            log[caseid] = [[],[],[]]\n",
    "\n",
    "        log[caseid][0].append(task)\n",
    "        log[caseid][1].append(timestamp)\n",
    "        log[caseid][2].append(day)\n",
    "\n",
    "file.close()\n",
    "os.remove('fixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise(iterable):\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_names = list(data_train['event concept:name'].unique())\n",
    "event_names.append('New Event')\n",
    "combs = []\n",
    "\n",
    "for p in itertools.product(event_names, repeat=2):\n",
    "    combs.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "pbar = ProgressBar()\n",
    "\n",
    "for i in pbar(log.keys()):\n",
    "    ID = []\n",
    "    stamps = []\n",
    "    for pairID, stamp in zip(pairwise(log[i][0]), pairwise(log[i][1])):\n",
    "        ID.append(pairID)\n",
    "        stamps.append(stamp)\n",
    "            \n",
    "    log[i].append(ID)\n",
    "    log[i].append(stamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "pbar = ProgressBar()\n",
    "count=0\n",
    "\n",
    "for i in pbar(log.keys()):\n",
    "    count=0\n",
    "    for perm in log[i][3]:\n",
    "        index = log[i][3].index(perm)\n",
    "        if index == 0:\n",
    "            log[i][3].insert(0, ('New Event', log[i][3][index][0]))\n",
    "            \n",
    "    for count in range(len(log[i][4])):\n",
    "        stamp = log[i][4][count]\n",
    "        if count == 0:\n",
    "            log[i][4].insert(0, (stamp[0], stamp[0]))\n",
    "            \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeDiff(tupl):\n",
    "    \n",
    "    datetimeFormat = '%Y-%m-%d'\n",
    "    diff = datetime.datetime.strptime(tupl[0], datetimeFormat)\\\n",
    "    - datetime.datetime.strptime(tupl[1], datetimeFormat)\n",
    "    \n",
    "    return abs(diff.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listCount(lst: list): \n",
    "    cases = list(data_train['event concept:name'].unique())  # list of all unique event names\n",
    "    cases.append('New Event')\n",
    "    best = 0\n",
    "    for x in cases:\n",
    "        current = lst.count(x)\n",
    "        if current >= best:\n",
    "            best = current\n",
    "            str_best = x\n",
    "    return str_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "pbar = ProgressBar() \n",
    "\n",
    "comb_times = {}\n",
    "\n",
    "for comb in pbar(combs):\n",
    "    day_list = [[], [], [], [], [], [], []]\n",
    "\n",
    "    for case in log.keys():\n",
    "        if comb in log[case][3]:     \n",
    "            index = log[case][3].index(comb)\n",
    "            day = int(log[case][2][index])\n",
    "\n",
    "            if index < (len(log[case][3]) - 1):\n",
    "                nxt_event = log[case][3][index+1][1]  # we need the second item of the tuple, bc item 1 is repeated\n",
    "                day_list[day].append(nxt_event)\n",
    "\n",
    "            elif index == (len(log[case][3]) - 1):\n",
    "                nxt_event = 'New Event'\n",
    "                day_list[day].append(nxt_event)\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    comb_times[comb] = day_list\n",
    "\n",
    "    for i in range(len(day_list)):\n",
    "        comb_times[comb][i] = listCount(comb_times[comb][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['event time:timestamp'] = pd.to_datetime(data_test['event time:timestamp'])\n",
    "\n",
    "data_test['event time:timestamp'] = pd.to_datetime(data_test['event time:timestamp'])\n",
    "\n",
    "data_test = data_test.sort_values(by=['case concept:name', 'event time:timestamp'])\n",
    "\n",
    "data_test['day_of_week'] = data_test['event time:timestamp'].dt.dayofweek\n",
    "\n",
    "data_test.to_csv(\"fixed_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_log = dict()\n",
    "\n",
    "\n",
    "with open('fixed_test.csv', 'r') as file_test:\n",
    "    next(file_test)\n",
    "    for line in file_test:\n",
    "        line = line.strip()\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        parts = line.split(',')\n",
    "\n",
    "        caseid = parts[2]\n",
    "\n",
    "        task = parts[3]\n",
    "        timestamp = parts[5]\n",
    "        day = parts[6]\n",
    "\n",
    "        if caseid not in t_log:\n",
    "            t_log[caseid] = [[],[],[]]\n",
    "\n",
    "        t_log[caseid][0].append(task)\n",
    "        t_log[caseid][1].append(timestamp)\n",
    "        t_log[caseid][2].append(day)\n",
    "file.close()\n",
    "os.remove('fixed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Fixing a bug of cases that are in the test data but are incomplete due to the train-test split.\"\"\"\n",
    "\n",
    "bugs = []\n",
    "\n",
    "for i in t_log.keys():\n",
    "    if len(t_log[i][0]) == 1:\n",
    "        bugs.append(i)\n",
    "            \n",
    "for x in bugs:\n",
    "    del t_log[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  new dictionary that will contain for every position(key) the observed traces and next events for each trace(values)\n",
    "#  so case [A, B, C] would be saved as {0:[[A],[B]], 1: [[A,B], [C]], 2: [[A, B, C], [New Case]]} \n",
    "train_data = {} \n",
    "\n",
    "for i in log.keys():\n",
    "    count = 0\n",
    "    for x in log[i][0]:\n",
    "        case = log[i][0]\n",
    "        #ind = log[i][0].index(x)\n",
    "        \n",
    "        if count not in train_data:  # making the two lists in the dictionary\n",
    "            train_data[count] = [[],[]]  # list 1 is all for all traces of the position, list 2 is for all next events\n",
    "        \n",
    "        \n",
    "        train_data[count][0].append(case[:count+1])  # appending the trace\n",
    "        \n",
    "        if count < len(case)-1:\n",
    "            train_data[count][1].append(case[count+1])  # appending the next event of the trace\n",
    "            \n",
    "        elif count == len(case)-1:\n",
    "            train_data[count][1].append('New Case')\n",
    "            \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the train_data you have all positions observed in the training set, they are the keys! \n",
    "\n",
    "That means, train_data[0] is for position 0, train_data[1] is for 1 and so on. \n",
    "\n",
    "Each position contains a list which has two sublists.\n",
    "- sublist 1: all observed traces up to the position. \n",
    "- sublist 2: all real next events for the above mentioned traces. Indexes match!\n",
    "\n",
    "So, train_data[2][0] has all traces observed for position 3 and train_data[2][1] has all next events for these traces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What you want to do is to take the most frequent event in the train_data[position][1]. There is a function in this notebook listCount() that takes list as an argument and its going to do it for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After that you need to use that as a prediction together with the permutations. You can do it by checking which one performs better for which position and then picking the one with the higher acc for that position (check it on the training data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can see the adding predictions section for the DT and how all events of a trace are split (look at the double for loop, namely - current_encoded[:(len(train_data))]. You will need that to match the traces up to current event with the ones from train_data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Once you are all done, please delete the explanation cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "pbar = ProgressBar()\n",
    "\n",
    "for i in pbar(t_log.keys()):\n",
    "    ID = []\n",
    "    stamps = []\n",
    "    for pairID, stamp in zip(pairwise(t_log[i][0]), pairwise(t_log[i][1])):\n",
    "        ID.append(pairID)\n",
    "        stamps.append(stamp)\n",
    "\n",
    "    t_log[i].append(ID)\n",
    "    t_log[i].append(stamps)\n",
    "\n",
    "pbar = ProgressBar()\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "for i in pbar(t_log.keys()):\n",
    "    count = 0\n",
    "    for perm in t_log[i][3]:\n",
    "        index = t_log[i][3].index(perm)\n",
    "        if index == 0:\n",
    "            t_log[i][3].insert(0, ('New Event', t_log[i][3][index][0]))\n",
    "\n",
    "    for count in range(len(t_log[i][4])):\n",
    "        stamp = t_log[i][4][count]\n",
    "        if count == 0:\n",
    "            t_log[i][4].insert(0, (stamp[0], stamp[0]))\n",
    "\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "pbar = ProgressBar()\n",
    "\n",
    "for i in pbar(t_log.keys()):\n",
    "    # Add the real time differences\n",
    "    real_diff = []\n",
    "    for t in t_log[i][4]:\n",
    "        real_diff.append(timeDiff(t))\n",
    "    t_log[i].extend([real_diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Adding predictions based on the combination with respect to the week. \"\"\"\n",
    "\n",
    "for i in t_log.keys():\n",
    "    current = t_log[i][3]\n",
    "    prediction = []\n",
    "\n",
    "    for perm in current:\n",
    "        index = current.index(perm)\n",
    "        day = int(t_log[i][2][index])\n",
    "        current_prediction = comb_times[perm][day]\n",
    "\n",
    "        if current_prediction != 0:\n",
    "            prediction.append(current_prediction)\n",
    "        else:\n",
    "            merged_list = list(itertools.chain.from_iterable(comb_times[perm]))\n",
    "            pred = listCount(merged_list)\n",
    "            prediction.append(pred)\n",
    "\n",
    "    t_log[i].extend([prediction])\n",
    "\n",
    "    current_real = []\n",
    "\n",
    "    for x in t_log[i][0]:\n",
    "        if t_log[i][0].index(x) == 0:\n",
    "            current_real.append('New Event')\n",
    "        else:\n",
    "            current_real.append(x)\n",
    "    t_log[i].extend([current_real])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Storing all time differences for every combination.\"\"\"\n",
    "\n",
    "pbar = ProgressBar()\n",
    "\n",
    "times = {}\n",
    "for comb in pbar(combs):\n",
    "    for case in log.keys():\n",
    "        if comb in log[case][3]:\n",
    "            count = log[case][3].index(comb)\n",
    "            diff = timeDiff(log[case][4][count])\n",
    "            if comb not in times:\n",
    "                times[comb] = []\n",
    "                times[comb].append(diff)\n",
    "            else:\n",
    "                times[comb].append(diff)\n",
    "        else:\n",
    "            pass\n",
    "    if comb in times.keys():\n",
    "        times[comb] = int(np.ceil(np.mean(times[comb])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Prediction for time difference, we check whether event is last and then predict 0 for it!\"\"\"\n",
    "for i in t_log.keys():\n",
    "    time_pred = []\n",
    "    for ev, pred, day in zip(t_log[i][0], t_log[i][6], t_log[i][2]):\n",
    "        last = len(t_log[i][0]) - 1\n",
    "\n",
    "        if t_log[i][0].index(ev) == last:\n",
    "            time_pred.append(0)\n",
    "        elif pred == 'New Event':\n",
    "            time_pred.append(0)\n",
    "        elif (ev, pred) in times:\n",
    "            if int(day) + times[(ev, pred)] % 7 == 5:\n",
    "                time_pred.append(times[(ev, pred)] + 2)\n",
    "            elif int(day) + times[(ev, pred)] % 7 == 6:\n",
    "                time_pred.append(times[(ev, pred)] + 1)\n",
    "            else:\n",
    "                time_pred.append(times[(ev, pred)])\n",
    "\n",
    "    t_log[i].extend([time_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a dataframe with the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for event prediction TEST SET: 60.0%\n",
      "Root mean squared error for time difference prediction TEST SET: 156.63\n"
     ]
    }
   ],
   "source": [
    "case_names = []\n",
    "event_names = []\n",
    "timestamp = []\n",
    "p_event = []\n",
    "current_real = []\n",
    "\n",
    "real_diff = []\n",
    "pred_diff = []\n",
    "\n",
    "for i in t_log.keys():\n",
    "    for x in range(len(t_log[i][0])):\n",
    "        case_names.append(i)\n",
    "        event_names.append(t_log[i][0][x])\n",
    "        timestamp.append(t_log[i][1][x])\n",
    "        p_event.append(t_log[i][6][x])\n",
    "        current_real.append(t_log[i][7][x])\n",
    "\n",
    "        real_diff.append(t_log[i][5][x])\n",
    "        pred_diff.append(t_log[i][8][x])\n",
    "\n",
    "real_diff.append(0)\n",
    "\n",
    "frame_dict = {'Case_ID': case_names, 'Event_Name': event_names,\n",
    "              'TimeStamp': timestamp, 'Current_Event': current_real, 'Predicted_Event': p_event,\n",
    "              'Real_Diff': real_diff[1:], 'Predicted_Diff': pred_diff}\n",
    "predicted_df = pd.DataFrame.from_dict(frame_dict)\n",
    "\n",
    "event_real = np.array(predicted_df['Current_Event'])\n",
    "event_pred = np.array(predicted_df['Predicted_Event'])\n",
    "event_real = event_real[1:]\n",
    "event_pred = event_pred[:-1]\n",
    "\n",
    "acc = accuracy_score(event_real, event_pred)\n",
    "print('Accuracy for event prediction TEST SET: {}%'.format(round(acc, 2) * 100))\n",
    "\n",
    "time_real = np.array(predicted_df['Real_Diff'])\n",
    "time_pred = np.array(predicted_df['Predicted_Diff'])\n",
    "\n",
    "time_pred = time_pred\n",
    "time_real = time_real\n",
    "\n",
    "rms = np.sqrt(mean_squared_error(time_real, time_pred))\n",
    "print('Root mean squared error for time difference prediction TEST SET: {}'.format(round(rms, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 112.49065804481506 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
