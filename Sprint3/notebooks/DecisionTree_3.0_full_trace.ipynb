{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree predicting the next event of a case - Full Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from progressbar import ProgressBar\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('./data/road-train-pre.csv', error_bad_lines=False)\n",
    "data_test = pd.read_csv('./data/road-test-pre.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['event time:timestamp'] = pd.to_datetime(data_train['event time:timestamp'])\n",
    "data_train = data_train.sort_values(by=['case concept:name', 'event time:timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['event time:timestamp'] = pd.to_datetime(data_test['event time:timestamp'])\n",
    "data_test = data_test.sort_values(by=['case concept:name', 'event time:timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.to_csv(\"fixed.csv\")\n",
    "\n",
    "log = dict()  # dictionary that contains all information for a case - key: case name; values: events, timestamps\n",
    "with open('fixed.csv', 'r') as file:\n",
    "    next(file)\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        parts = line.split(',')\n",
    "        caseid = parts[2]\n",
    "\n",
    "        task = parts[3]\n",
    "        timestamp = parts[5]\n",
    "\n",
    "        if caseid not in log:\n",
    "            log[caseid] = [[],[]]\n",
    "\n",
    "        log[caseid][0].append(task)  # adding the events as a list into the dictionary\n",
    "        log[caseid][1].append(timestamp)  # adding the timestamps as a list into the dictionary\n",
    "        \n",
    "file.close()\n",
    "\n",
    "os.remove('fixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in log.keys():  # updating the dictionary to contain also all next events \n",
    "    current = log[i][0]  # recording the cuurent case' events\n",
    "    \n",
    "    real_next = current[1:]  # next real events\n",
    "    real_next.append('New Case')  # adding a 'new case' as real next event for every last event\n",
    "    \n",
    "    log[i].append(real_next)  # adding the real next events to the log file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Repeating the same process from above on the test data.\n",
    "\n",
    "data_test.to_csv(\"fixed_test.csv\")\n",
    "\n",
    "log_test = dict()\n",
    "with open('fixed_test.csv', 'r') as file:\n",
    "    next(file)\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        parts = line.split(',')\n",
    "        caseid = parts[2]\n",
    "        \n",
    "        task = parts[3]\n",
    "        timestamp = parts[5]\n",
    "\n",
    "        if caseid not in log_test:\n",
    "            log_test[caseid] = [[],[]]\n",
    "\n",
    "        log_test[caseid][0].append(task)\n",
    "        log_test[caseid][1].append(timestamp)\n",
    "        \n",
    "file.close()\n",
    "\n",
    "os.remove('fixed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Fixing a bug of cases that are in the test data but are incomplete due to the train-test split.\"\"\"\n",
    "\n",
    "bugs = []\n",
    "\n",
    "for i in log_test.keys():  #  recording the cases which have events cut because of the train - test split\n",
    "    if len(log_test[i][0]) == 1:\n",
    "        bugs.append(i)\n",
    "            \n",
    "for x in bugs:  # deleting the above mentioned events \n",
    "    del log_test[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in log_test.keys():\n",
    "    current = log_test[i][0]  # current case' events\n",
    "    \n",
    "    real_next = current[1:]  # next real events\n",
    "    real_next.append('New Case')  # adding a 'new case' as real next event for every last event\n",
    "    log_test[i].append(real_next) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Storing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  new dictionary that will contain for every position(key) the observed traces and next events for each trace(values)\n",
    "#  so case [A, B, C] would be saved as {0:[[A],[B]], 1: [[A,B], [C]], 2: [[A, B, C], [New Case]]} \n",
    "train_data = {} \n",
    "\n",
    "for i in log.keys():\n",
    "    for x in log[i][0]:\n",
    "        case = log[i][0]\n",
    "        ind = log[i][0].index(x)\n",
    "        \n",
    "        if ind not in train_data:  # making the two lists in the dictionary\n",
    "            train_data[ind] = [[],[]]  # list 1 is all for all traces of the position, list 2 is for all next events\n",
    "        \n",
    "        \n",
    "        train_data[ind][0].append(case[:ind+1])  # appending the trace\n",
    "        \n",
    "        if ind < len(case)-1:\n",
    "            train_data[ind][1].append(case[ind+1])  # appending the next event of the trace\n",
    "            \n",
    "        elif ind == len(case)-1:\n",
    "            train_data[ind][1].append('New Case')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  repeating the same process on the test data\n",
    "test_data = {} \n",
    "\n",
    "for i in log_test.keys():\n",
    "    for x in log_test[i][0]:\n",
    "        case = log_test[i][0]\n",
    "        ind = log_test[i][0].index(x)\n",
    "        \n",
    "        if ind not in test_data:\n",
    "            test_data[ind] = [[],[]]\n",
    "        \n",
    "        \n",
    "        test_data[ind][0].append(case[:ind+1])  # appending the trace\n",
    "        \n",
    "        if ind < len(case)-1:\n",
    "            test_data[ind][1].append(case[ind+1])  # appending the next event of the trace\n",
    "            \n",
    "        elif ind == len(case)-1:\n",
    "            test_data[ind][1].append('New Case')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoding all unique event names of all the data into integers\n",
    "\n",
    "cases = list(data_train['event concept:name'].unique()) + list(data_test['event concept:name'].unique())  # all events\n",
    "cases.append('New Case')  #  adding the 'New Case' because we predict next event is going to be new case\n",
    "cases = list(set(cases)) \n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(cases)  # encoding all event names into integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "pbar = ProgressBar()\n",
    "\n",
    "for i in pbar(train_data.keys()):  # the dictionaries from above are encoded into integers \n",
    "    \n",
    "    encoded = []\n",
    "    for trace in train_data[i][0]:  # encoding all strings of a trace, can be multiple if case lenght is more than 2\n",
    "        local_encoded = []\n",
    "        for event in trace:\n",
    "            local_encoded.append(int(le.transform([event])))  # transforming into integer\n",
    "        encoded.append(local_encoded)\n",
    "    \n",
    "    train_data[i][0] = np.array(encoded)  # making the list with integers into array so the tree can take it\n",
    "    \n",
    "    \n",
    "    encoded_next = []  # encoding all strings of next events for a trace, its always length 1 !\n",
    "    for g in train_data[i][1]:\n",
    "        encoded_next.append(int(le.transform([g])))  # transforming into integer\n",
    "                            \n",
    "                            \n",
    "    train_data[i][1] = np.array(encoded_next)  #  making the list with integers into array\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "# repeating the procedure from above on the test data\n",
    "\n",
    "pbar = ProgressBar()\n",
    "\n",
    "for i in pbar(test_data.keys()):\n",
    "    \n",
    "    encoded = []\n",
    "    for trace in test_data[i][0]:\n",
    "        local_encoded = []\n",
    "        for event in trace:\n",
    "            local_encoded.append(int(le.transform([event])))\n",
    "        encoded.append(local_encoded)\n",
    "    \n",
    "    test_data[i][0] = np.array(encoded)\n",
    "    \n",
    "    \n",
    "    encoded_next = []\n",
    "    for g in test_data[i][1]:\n",
    "        encoded_next.append(int(le.transform([g])))\n",
    "                            \n",
    "                            \n",
    "    test_data[i][1] = np.array(encoded_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for training decision tree for any given position (as long as the position is in the train data)\n",
    "\n",
    "def decision_tree(pos):\n",
    "\n",
    "    x_train= train_data[pos][0]\n",
    "    y_train= train_data[pos][1]\n",
    "\n",
    "    classifier = DecisionTreeClassifier()\n",
    "    classifier.fit(x_train, y_train)\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = {}  # dictionary to contain all decision trees given the position\n",
    "#  key - position, value - decision tree for that position\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    if i >= len(train_data) - 1:\n",
    "        predictors[i] = decision_tree(len(train_data) - 1)\n",
    "        \n",
    "    else:\n",
    "        predictors[i] = decision_tree(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Adding predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "pbar = ProgressBar()\n",
    "\n",
    "for i in pbar(log_test.keys()):  # adding an array with the encoding to the log_test dict. for every case in the test \n",
    "    current = log_test[i][0]\n",
    "    \n",
    "    \n",
    "    encoded = []  # list will contain all event names encoded into integers\n",
    "    for g in current:\n",
    "        encoded.append(int(le.transform([g])))\n",
    "    encoded = np.array(encoded)\n",
    "    log_test[i].append(encoded)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "pbar = ProgressBar()\n",
    "for i in pbar(log_test.keys()):  # making predictions for every case in the log_test dict\n",
    "    \n",
    "    current_encoded = log_test[i][3]\n",
    "    predictions = []  # list that will contain all predictions for a given case\n",
    "    \n",
    "    for x in current_encoded:\n",
    "        ind = list(current_encoded).index(x)\n",
    "        \n",
    "        \n",
    "        # the if-else is a checks whether the case length is more than any case length observed in the train data\n",
    "        if ind >= len(train_data) - 1: # if its in the train data we call the appropriate decision tree\n",
    "            \n",
    "            \n",
    "            tree = predictors[len(train_data) - 1]  # calling the right tree given the position\n",
    "            p = current_encoded[:(len(train_data))]  # taking the trace\n",
    "            p = p.reshape(1, -1)\n",
    "            pred = tree.predict(p)  # making a prediction \n",
    "            pred_string = le.inverse_transform(pred)[0]  # transforming the prediction into a string\n",
    "            predictions.append(pred_string)  # appending the prediction as a string to the log_test data\n",
    "            \n",
    "            \n",
    "            \n",
    "        else:  # if its not in the train data then we use the last observed decision tree from the train data\n",
    "        \n",
    "            tree = predictors[ind]  # calling the right tree given the position\n",
    "            p = current_encoded[:ind+1]  # taking the trace\n",
    "            p = p.reshape(1, -1)  # we need to do that, idk why\n",
    "            pred = tree.predict(p)  # making a prediction\n",
    "            pred_string = le.inverse_transform(pred)[0]  # transforming the prediction into a string\n",
    "            predictions.append(pred_string)  # appending the prediction as a string to the log_test data \n",
    "        \n",
    "    log_test[i].append(predictions)  # adding all predictions to the log_test of the current case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for event prediction TEST SET: 69.0%\n"
     ]
    }
   ],
   "source": [
    "# making lists for every column we will have in the frame\n",
    "case_names = []\n",
    "event_names = []\n",
    "timestamp = []\n",
    "p_event = []\n",
    "current_real = []\n",
    "\n",
    "for i in log_test.keys():  # appending the right things to every list from the log_test file\n",
    "    for x in range(len(log_test[i][0])):\n",
    "        case_names.append(i)\n",
    "        event_names.append(log_test[i][0][x])\n",
    "        timestamp.append(log_test[i][1][x])\n",
    "        p_event.append(log_test[i][4][x])\n",
    "        current_real.append(log_test[i][2][x])\n",
    "\n",
    "# dictionary that will be used to make the frame\n",
    "frame_dict = {'Case_ID': case_names, 'Event_Name': event_names,\n",
    "              'TimeStamp': timestamp, 'Next_Event': current_real, 'Predicted_Event': p_event}\n",
    "predicted_df = pd.DataFrame.from_dict(frame_dict)  # making a frame \n",
    "\n",
    "event_real = np.array(predicted_df['Next_Event'])  # taking next event col. as an array\n",
    "event_pred = np.array(predicted_df['Predicted_Event'])  # taking the predictions as an array \n",
    "\n",
    "acc = accuracy_score(event_real, event_pred)  # calculates the accuracy based on the both arrays\n",
    "print('Accuracy for event prediction TEST SET: {}%'.format(round(acc, 2) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 233.47721219062805 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case_ID</th>\n",
       "      <th>Event_Name</th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>Next_Event</th>\n",
       "      <th>Predicted_Event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A28905</td>\n",
       "      <td>Create Fine</td>\n",
       "      <td>2009-09-25</td>\n",
       "      <td>Send Fine</td>\n",
       "      <td>Send Fine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A28905</td>\n",
       "      <td>Send Fine</td>\n",
       "      <td>2010-01-19</td>\n",
       "      <td>Insert Fine Notification</td>\n",
       "      <td>Insert Fine Notification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A28905</td>\n",
       "      <td>Insert Fine Notification</td>\n",
       "      <td>2010-08-02</td>\n",
       "      <td>Add penalty</td>\n",
       "      <td>Add penalty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A28905</td>\n",
       "      <td>Add penalty</td>\n",
       "      <td>2010-09-04</td>\n",
       "      <td>Send for Credit Collection</td>\n",
       "      <td>Send for Credit Collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A28905</td>\n",
       "      <td>Send for Credit Collection</td>\n",
       "      <td>2012-03-26</td>\n",
       "      <td>New Case</td>\n",
       "      <td>New Case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96156</th>\n",
       "      <td>V19305</td>\n",
       "      <td>Send Appeal to Prefecture</td>\n",
       "      <td>2012-02-24</td>\n",
       "      <td>New Case</td>\n",
       "      <td>New Case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96157</th>\n",
       "      <td>V19308</td>\n",
       "      <td>Create Fine</td>\n",
       "      <td>2011-07-10</td>\n",
       "      <td>Send Fine</td>\n",
       "      <td>Send Fine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96158</th>\n",
       "      <td>V19308</td>\n",
       "      <td>Send Fine</td>\n",
       "      <td>2012-01-30</td>\n",
       "      <td>Insert Fine Notification</td>\n",
       "      <td>Insert Fine Notification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96159</th>\n",
       "      <td>V19308</td>\n",
       "      <td>Insert Fine Notification</td>\n",
       "      <td>2012-02-24</td>\n",
       "      <td>Add penalty</td>\n",
       "      <td>Add penalty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96160</th>\n",
       "      <td>V19308</td>\n",
       "      <td>Add penalty</td>\n",
       "      <td>2012-04-24</td>\n",
       "      <td>New Case</td>\n",
       "      <td>Send for Credit Collection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96161 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Case_ID                  Event_Name   TimeStamp  \\\n",
       "0      A28905                 Create Fine  2009-09-25   \n",
       "1      A28905                   Send Fine  2010-01-19   \n",
       "2      A28905    Insert Fine Notification  2010-08-02   \n",
       "3      A28905                 Add penalty  2010-09-04   \n",
       "4      A28905  Send for Credit Collection  2012-03-26   \n",
       "...       ...                         ...         ...   \n",
       "96156  V19305   Send Appeal to Prefecture  2012-02-24   \n",
       "96157  V19308                 Create Fine  2011-07-10   \n",
       "96158  V19308                   Send Fine  2012-01-30   \n",
       "96159  V19308    Insert Fine Notification  2012-02-24   \n",
       "96160  V19308                 Add penalty  2012-04-24   \n",
       "\n",
       "                       Next_Event             Predicted_Event  \n",
       "0                       Send Fine                   Send Fine  \n",
       "1        Insert Fine Notification    Insert Fine Notification  \n",
       "2                     Add penalty                 Add penalty  \n",
       "3      Send for Credit Collection  Send for Credit Collection  \n",
       "4                        New Case                    New Case  \n",
       "...                           ...                         ...  \n",
       "96156                    New Case                    New Case  \n",
       "96157                   Send Fine                   Send Fine  \n",
       "96158    Insert Fine Notification    Insert Fine Notification  \n",
       "96159                 Add penalty                 Add penalty  \n",
       "96160                    New Case  Send for Credit Collection  \n",
       "\n",
       "[96161 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
