{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree predicting the next event of a case - Full Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from progressbar import ProgressBar\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('./data/road-train-pre.csv', error_bad_lines=False)\n",
    "data_test = pd.read_csv('./data/road-test-pre.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['event time:timestamp'] = pd.to_datetime(data_train['event time:timestamp'])\n",
    "data_train = data_train.sort_values(by=['case concept:name', 'event time:timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['event time:timestamp'] = pd.to_datetime(data_test['event time:timestamp'])\n",
    "data_test = data_test.sort_values(by=['case concept:name', 'event time:timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.to_csv(\"fixed.csv\")\n",
    "\n",
    "file = open('fixed.csv', 'r') \n",
    "log = dict()  # dictionary that contains all information for a case - key: case name; values: events, timestamps\n",
    "with open('fixed.csv', 'r') as file:\n",
    "    next(file)\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        parts = line.split(',')\n",
    "        caseid = parts[2]\n",
    "\n",
    "        task = parts[3]\n",
    "        timestamp = parts[5]\n",
    "\n",
    "        if caseid not in log:\n",
    "            log[caseid] = [[],[]]\n",
    "\n",
    "        log[caseid][0].append(task)  # adding the events as a list into the dictionary\n",
    "        log[caseid][1].append(timestamp)  # adding the timestamps as a list into the dictionary\n",
    "        \n",
    "file.close()\n",
    "\n",
    "os.remove('fixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in log.keys():  # updating the dictionary to contain also all next events \n",
    "    current = log[i][0]  # recording the cuurent case' events\n",
    "    \n",
    "    real_next = current[1:]  # next real events\n",
    "    real_next.append('New Case')  # adding a 'new case' as real next event for every last event\n",
    "    \n",
    "    log[i].append(real_next)  # adding the real next events to the log file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Repeating the same process from above on the test data.\n",
    "\n",
    "data_test.to_csv(\"fixed_test.csv\")\n",
    "\n",
    "file = open('fixed_test.csv', 'r')\n",
    "log_test = dict()\n",
    "with open('fixed_test.csv', 'r') as file:\n",
    "    next(file)\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        parts = line.split(',')\n",
    "        caseid = parts[2]\n",
    "        \n",
    "        task = parts[3]\n",
    "        timestamp = parts[5]\n",
    "\n",
    "        if caseid not in log_test:\n",
    "            log_test[caseid] = [[],[]]\n",
    "\n",
    "        log_test[caseid][0].append(task)\n",
    "        log_test[caseid][1].append(timestamp)\n",
    "        \n",
    "file.close()\n",
    "\n",
    "os.remove('fixed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Fixing a bug of cases that are in the test data but are incomplete due to the train-test split.\"\"\"\n",
    "\n",
    "bugs = []\n",
    "\n",
    "for i in log_test.keys():  #  recording the cases which have events cut because of the train - test split\n",
    "    if len(log_test[i][0]) == 1:\n",
    "        bugs.append(i)\n",
    "            \n",
    "for x in bugs:  # deleting the above mentioned events \n",
    "    del log_test[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in log_test.keys():\n",
    "    current = log_test[i][0]  # current case' events\n",
    "    \n",
    "    real_next = current[1:]  # next real events\n",
    "    real_next.append('New Case')  # adding a 'new case' as real next event for every last event\n",
    "    log_test[i].append(real_next) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Storing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  new dictionary that will contain for every position(key) the observed traces and next events for each trace(values)\n",
    "#  so case [A, B, C] would be saved as {0:[[A],[B]], 1: [[A,B], [C]], 2: [[A, B, C], [New Case]]} \n",
    "train_data = {} \n",
    "\n",
    "for i in log.keys():\n",
    "    count = 0\n",
    "    for x in log[i][0]:\n",
    "        case = log[i][0]\n",
    "        #ind = log[i][0].index(x)\n",
    "        \n",
    "        if count not in train_data:  # making the two lists in the dictionary\n",
    "            train_data[count] = [[],[]]  # list 1 is all for all traces of the position, list 2 is for all next events\n",
    "        \n",
    "        \n",
    "        train_data[count][0].append(case[:count+1])  # appending the trace\n",
    "        \n",
    "        if count < len(case)-1:\n",
    "            train_data[count][1].append(case[count+1])  # appending the next event of the trace\n",
    "            \n",
    "        elif count == len(case)-1:\n",
    "            train_data[count][1].append('New Case')\n",
    "            \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  repeating the same process on the test data\n",
    "test_data = {} \n",
    "\n",
    "for i in log_test.keys():\n",
    "    count = 0\n",
    "    for x in log_test[i][0]:\n",
    "        case = log_test[i][0]\n",
    "        #ind = log_test[i][0].index(x)\n",
    "        \n",
    "        if count not in test_data:\n",
    "            test_data[count] = [[],[]]\n",
    "        \n",
    "        \n",
    "        test_data[count][0].append(case[:count+1])  # appending the trace\n",
    "        \n",
    "        if count < len(case)-1:\n",
    "            test_data[count][1].append(case[count+1])  # appending the next event of the trace\n",
    "            \n",
    "        elif count == len(case)-1:\n",
    "            test_data[count][1].append('New Case')\n",
    "            \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding all unique event names of all the data into integers\n",
    "\n",
    "cases = list(data_train['event concept:name'].unique()) + list(data_test['event concept:name'].unique())  # all events\n",
    "cases.append('New Case')  #  adding the 'New Case' because we predict next event is going to be new case\n",
    "cases = list(set(cases)) \n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(cases)  # encoding all event names into integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = ProgressBar()\n",
    "\n",
    "for i in pbar(train_data.keys()):  # the dictionaries from above are encoded into integers \n",
    "    \n",
    "    encoded = []\n",
    "    for trace in train_data[i][0]:  # encoding all strings of a trace, can be multiple if case lenght is more than 2\n",
    "        local_encoded = []\n",
    "        for event in trace:\n",
    "            local_encoded.append(int(le.transform([event])))  # transforming into integer\n",
    "        encoded.append(local_encoded)\n",
    "    \n",
    "    train_data[i][0] = np.array(encoded)  # making the list with integers into array so the tree can take it\n",
    "    \n",
    "    \n",
    "    encoded_next = []  # encoding all strings of next events for a trace, its always length 1 !\n",
    "    for g in train_data[i][1]:\n",
    "        encoded_next.append(int(le.transform([g])))  # transforming into integer\n",
    "                            \n",
    "                            \n",
    "    train_data[i][1] = np.array(encoded_next)  #  making the list with integers into array\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeating the procedure from above on the test data\n",
    "\n",
    "pbar = ProgressBar()\n",
    "\n",
    "for i in pbar(test_data.keys()):\n",
    "    \n",
    "    encoded = []\n",
    "    for trace in test_data[i][0]:\n",
    "        local_encoded = []\n",
    "        for event in trace:\n",
    "            local_encoded.append(int(le.transform([event])))\n",
    "        encoded.append(local_encoded)\n",
    "    \n",
    "    test_data[i][0] = np.array(encoded)\n",
    "    \n",
    "    \n",
    "    encoded_next = []\n",
    "    for g in test_data[i][1]:\n",
    "        encoded_next.append(int(le.transform([g])))\n",
    "                            \n",
    "                            \n",
    "    test_data[i][1] = np.array(encoded_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for training decision tree for any given position (as long as the position is in the train data)\n",
    "\n",
    "def decision_tree(pos):\n",
    "\n",
    "    x_train= train_data[pos][0]\n",
    "    y_train= train_data[pos][1]\n",
    "    \n",
    "\n",
    "    classifier = DecisionTreeClassifier()\n",
    "    classifier.fit(x_train, y_train)\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = {}  # dictionary to contain all decision trees given the position\n",
    "#  key - position, value - decision tree for that position\n",
    "\n",
    "for i in test_data.keys():\n",
    "    if i > len(train_data) - 1:\n",
    "        predictors[i] = decision_tree(len(train_data) - 1)\n",
    "        \n",
    "    else:\n",
    "        predictors[i] = decision_tree(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Adding predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = ProgressBar()\n",
    "\n",
    "for i in pbar(log_test.keys()):  # adding an array with the encoding to the log_test dict. for every case in the test \n",
    "    current = log_test[i][0]\n",
    "    \n",
    "    \n",
    "    encoded = []  # list will contain all event names encoded into integers\n",
    "    for g in current:\n",
    "        encoded.append(int(le.transform([g])))\n",
    "    encoded = np.array(encoded)\n",
    "    log_test[i].append(encoded)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW PART, CHECK CAREFULLY. EVERYTHING WORKS WITH THE FUNCTION BUT FINAL ACCURACY REMAINS THE SAME. COULD BE A \n",
    "# SMALL MISTAKE. THE FUNCTION IS CALLED IN THE END OF THE FOLLOWING CELL.\n",
    "\n",
    "def update_tree(case):\n",
    "    \n",
    "    case = case.tolist()\n",
    "    \n",
    "    count = 0\n",
    "    for x in case: # case is an array\n",
    "        if count not in train_data:  # making the two lists in the dictionary\n",
    "            train_data[count] = [np.array([]),np.array([])]  # list 1 is all for all traces of the position, list 2 is for all next events\n",
    "            \n",
    "        train_data[count][0] = train_data[count][0].tolist()\n",
    "        train_data[count][1] = train_data[count][1].tolist()\n",
    "        \n",
    "        train_data[count][0].append(case[:count+1])  # appending the trace\n",
    "        \n",
    "        if count < len(case)-1:\n",
    "            train_data[count][1].append(case[count+1])  # appending the next event of the trace\n",
    "            \n",
    "        elif count == len(case)-1:\n",
    "            train_data[count][1].append(int(le.transform(['New Case'])))\n",
    "            \n",
    "        train_data[count][0] = np.array(train_data[count][0])\n",
    "        train_data[count][1] = np.array(train_data[count][1])\n",
    "        \n",
    "        \n",
    "        predictors[count] = decision_tree(count)\n",
    "            \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = ProgressBar()\n",
    "for i in pbar(log_test.keys()):  # making predictions for every case in the log_test dict\n",
    "\n",
    "    current_encoded = log_test[i][3]\n",
    "    predictions = []  # list that will contain all predictions for a given case\n",
    "    count = 0\n",
    "    \n",
    "    for x in current_encoded:\n",
    "        \n",
    "        \n",
    "        # the if-else is a checks whether the case length is more than any case length observed in the train data\n",
    "        if count >= len(train_data) - 1: # if its in the train data we call the appropriate decision tree\n",
    "            \n",
    "            \n",
    "            tree = predictors[len(train_data) - 1]  # calling the right tree given the position\n",
    "            p = current_encoded[:(len(train_data))]  # taking the trace\n",
    "            p = p.reshape(1, -1)\n",
    "            pred = tree.predict(p)  # making a prediction \n",
    "            pred_string = le.inverse_transform(pred)[0]  # transforming the prediction into a string\n",
    "            predictions.append(pred_string)  # appending the prediction as a string to the log_test data\n",
    "            \n",
    "            \n",
    "            \n",
    "        else:  # if its not in the train data then we use the last observed decision tree from the train data\n",
    "        \n",
    "            tree = predictors[count]  # calling the right tree given the position\n",
    "            p = current_encoded[:count+1]  # taking the trace\n",
    "            p = p.reshape(1, -1)  # we need to do that, idk why\n",
    "            pred = tree.predict(p)  # making a prediction\n",
    "            pred_string = le.inverse_transform(pred)[0]  # transforming the prediction into a string\n",
    "            predictions.append(pred_string)  # appending the prediction as a string to the log_test data \n",
    "            \n",
    "        count += 1\n",
    "        \n",
    "    log_test[i].append(predictions)  # adding all predictions to the log_test of the current case\n",
    "    \n",
    "    \n",
    "    # UNCOMMENT THE LINE BELOW FOR ONLINE TRAINING\n",
    "    \n",
    "    #update_tree(current_encoded)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making lists for every column we will have in the frame\n",
    "case_names = []\n",
    "event_names = []\n",
    "timestamp = []\n",
    "p_event = []\n",
    "current_real = []\n",
    "\n",
    "for i in log_test.keys():  # appending the right things to every list from the log_test file\n",
    "    for x in range(len(log_test[i][0])):\n",
    "        case_names.append(i)\n",
    "        event_names.append(log_test[i][0][x])\n",
    "        timestamp.append(log_test[i][1][x])\n",
    "        p_event.append(log_test[i][-1][x])\n",
    "        current_real.append(log_test[i][2][x])\n",
    "\n",
    "# dictionary that will be used to make the frame\n",
    "frame_dict = {'Case_ID': case_names, 'Event_Name': event_names,\n",
    "              'TimeStamp': timestamp, 'Next_Event': current_real, 'Predicted_Event': p_event}\n",
    "predicted_df = pd.DataFrame.from_dict(frame_dict)  # making a frame \n",
    "\n",
    "event_real = np.array(predicted_df['Next_Event'])  # taking next event col. as an array\n",
    "event_pred = np.array(predicted_df['Predicted_Event'])  # taking the predictions as an array \n",
    "\n",
    "acc = accuracy_score(event_real, event_pred)  # calculates the accuracy based on the both arrays\n",
    "print('Accuracy for event prediction TEST SET: {}%'.format(round(acc, 2) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy per position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-- Accuracy per position on train data\\n')\n",
    "for i in train_data.keys():\n",
    "    \n",
    "    x_train = train_data[i][0]\n",
    "    y_train = train_data[i][1]\n",
    "    \n",
    "    tree = predictors[i]\n",
    "    \n",
    "    x_test = train_data[i][0]\n",
    "    y_test = train_data[i][1]\n",
    "    \n",
    "    y_pred = tree.predict(x_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print('-- Position:', i, '-- Acc:', '{}%'.format(round(acc, 2) * 100), '-- Cases:', len(x_test),\n",
    "          '-- Cases to train on:', len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-- Accuracy per position on test data\\n')\n",
    "for i in test_data.keys():\n",
    "    \n",
    "    x_test = test_data[i][0]\n",
    "    y_test = test_data[i][1]\n",
    "    \n",
    "    if i <= len(train_data) - 1:\n",
    "\n",
    "        tree = predictors[i]\n",
    "\n",
    "        y_pred = tree.predict(x_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print('-- Position:', i, '-- Acc:', '{}%'.format(round(acc, 2) * 100), '-- Cases:', len(x_test),\n",
    "             '-- Cases to train on:', len(train_data[i][0]) )\n",
    "        \n",
    "    elif i > len(train_data) - 1:\n",
    "        \n",
    "        new_trace = [x[:len(train_data)] for x in x_test]\n",
    "        tree = predictors[len(train_data) - 1]\n",
    "        y_pred = tree.predict(new_trace)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print('-- Position:', i, '-- Acc:', '{}%'.format(round(acc, 2) * 100), '-- Cases:', len(x_test), \n",
    "             '-- Cases to train on: 0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
